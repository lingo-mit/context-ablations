{"model_type": "gpt2",
 "vocab_size": 50257,
 "n_positions": 1024,
 "n_ctx": 1024,
 "n_embd": 768,
 "n_layer": 12,
 "n_head": 12,
 "activation_function": "gelu_new",
 "resid_pdrop": 0.1,
 "embd_pdrop": 0.1,
 "attn_pdrop": 0.1,
 "layer_norm_epsilon": 1e-5,
 "initializer_range": 0.02}
